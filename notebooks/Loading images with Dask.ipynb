{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading images with Dask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Welcome to this notebook, where we wil show how to process images bigger than memory in GPU.\n",
    "It uses Dask, Xarray, CuPy, Napari… and many others. The documentation of those projects is pretty good, and therefore this notebook is mainly a copy-paste of that documentation. And Stack overflow, of course.\n",
    "Let’s start with some imports:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from math import isqrt\n",
    "from typing import Tuple\n",
    "\n",
    "import cupy as cp\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import rioxarray as rx\n",
    "import xarray as xr\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from skimage.util import view_as_blocks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modify your settings here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_PATH=\"YOUR PATH HERE\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the cluster. It uses Dask-Cuda, from RAPIDS. The cluster must only be initialized once. Note the memory limit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster(device_memory_limit=\"1GB\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adjust and create the client. Note the chunk size. It has been tuned for my computer, but you can try other values. Also note that the backend is set to CuPy by default, despite rioxarray (we will se it later) is ignoring it, I think.\n",
    "\n",
    "You can see the client's dashboard. It is quite relaxing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dask.config.set({\n",
    "    \"array.backend\": \"cupy\",\n",
    "    \"array.chunk-size\": \"64MiB\"\n",
    "    })\n",
    "client = Client(cluster)\n",
    "client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I do not have a real model. But anyway, let's create a fake one. CuPy provides interoperability with TensorFlow, so adapting this for a Keras model should not be that difficult."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    @property\n",
    "    def input_shape(self) -> Tuple[int, int, int]:\n",
    "        return 299, 299, 3\n",
    "\n",
    "    @property\n",
    "    def output_shape(self) -> Tuple[int, int, int]:\n",
    "        return 1, 1, 3\n",
    "\n",
    "    def predict(self, images_to_predict: np.ndarray) -> np.ndarray:\n",
    "        # Create a fake model.\n",
    "        # Average per band. That will generate a valid visible image\n",
    "        # TODO: maybe first dimensions must be grouped\n",
    "        return np.mean(images_to_predict, axis=(2, 3))\n",
    "\n",
    "model = Model()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step when working with images is loading them. Yeah, obviously. This function loads all the images using rioxarray, and creates a big mosaic with all of them. Note that an xarray DataArray is returned. xarray is cool.\n",
    "\n",
    "Caveat: at the moment, only one image is loaded several times, and therefore Dask optimizes it. Real different images or image formats may behave in different ways.\n",
    "\n",
    "Also note the rioxarray warning. That library is though for gepospatial images, and it will complain if no geospatial data available. BUT, rioxarray creates xarray DataArray objects, using Dask arrays as backends, and honoring image chunks, and that is a good point. I think dask-image does not honour chunks.\n",
    "\n",
    "My test image is a hubble image downloaded from [here](https://esahubble.org/images/heic1502a/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_image_mosaic() -> xr.DataArray:\n",
    "    # https://esahubble.org/images/heic1502a/\n",
    "    base_image = BASE_PATH + '/data/heic1502a.tif'\n",
    "    rows = []\n",
    "    for row in range(8):\n",
    "        current_row = []\n",
    "        for col in range(8):\n",
    "            # Read and remove useless band\n",
    "            img = rx.open_rasterio(base_image,\n",
    "                                   parse_coordinates=False,\n",
    "                                   chunks='auto')\n",
    "            current_row.append(img)\n",
    "        row_array = xr.concat(current_row, dim='x')\n",
    "        rows.append(row_array)\n",
    "    image = xr.concat(rows, dim='y')\n",
    "\n",
    "    # Tidy the image\n",
    "    image = image.assign_coords({'band': ['red', 'green', 'blue']})\n",
    "    return image\n",
    "\n",
    "\n",
    "image_mosaic = get_image_mosaic()\n",
    "image_mosaic = image_mosaic.copy(deep=False, data=image_mosaic.data.map_blocks(cp.asarray))\n",
    "image_mosaic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Until now, there is not anything weird, we just loaded images. Now the image must be adapted to the model.\n",
    "\n",
    "Dask works splitting the image into chunks. Too big chunks, we blow the memory, too small chunks, it is slow. We determine the optimal chunk shape based on the desired chunk size, and reshape the image for having chunks with shapes multiples of the model shape.\n",
    "\n",
    "We also normalize the image to range \\[0, 1\\]. This is different in numpy than in cupy.\n",
    "\n",
    "Note the `da.map_blocks` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rechunk_for_model(image: xr.DataArray, model_shape: Tuple[int, int, int]) -> da.array:\n",
    "    # Get items to pad on rows\n",
    "    model_y = model_shape[0]\n",
    "    image_y = image.sizes['y']\n",
    "    remainder_y = image_y % model_y\n",
    "    pad_y = (0, 0)\n",
    "    if remainder_y != 0:\n",
    "        extra_y = model_y - remainder_y\n",
    "        pad_y = (0, extra_y)\n",
    "\n",
    "    # Get items to pad on cols\n",
    "    model_x = model_shape[1]\n",
    "    image_x = image.sizes['x']\n",
    "    remainder_x = image_x % model_x\n",
    "    pad_x = (0, 0)\n",
    "    if remainder_x != 0:\n",
    "        extra_x = model_x - remainder_x\n",
    "        pad_x = (0, extra_x)\n",
    "\n",
    "    # Pad the image\n",
    "    image = image.pad({\n",
    "        'y': pad_y,\n",
    "        'x': pad_x\n",
    "        },\n",
    "        constant_values=0)\n",
    "    image_y = image.sizes['y']\n",
    "    image_x = image.sizes['x']\n",
    "\n",
    "    # Rechunk in multiples of model size\n",
    "    # Calculate the optimal size for dims x and y, assuming band joins together\n",
    "    chunk_size = parse_bytes(dask.config.get('array.chunk-size'))\n",
    "    model_band = model_shape[2]\n",
    "    patch_size = model_y * model_x * model_band * image.data.itemsize\n",
    "    # Check how many patches will be for every chunk in dims y and x\n",
    "    num_patches = chunk_size // patch_size\n",
    "    y_patches_in_chunk = isqrt(num_patches)\n",
    "    x_patches_in_chunk = num_patches // y_patches_in_chunk\n",
    "    # Rechunk and send\n",
    "    image = image.transpose(\"y\", \"x\", \"band\")\n",
    "    image = image.chunk(chunks={\n",
    "        'y': y_patches_in_chunk * model_y,\n",
    "        'x': x_patches_in_chunk * model_x,\n",
    "        'band': -1})\n",
    "    return image\n",
    "\n",
    "def normalize_chunk(chunk: np.ndarray):\n",
    "    # Use this one for [-1, 1] normalization\n",
    "    # chunk = cp.float32(chunk.get()) / 255.0 * 2.0 - 1.0\n",
    "    chunk = cp.float32(chunk.get()) / 255.0\n",
    "    return chunk\n",
    "\n",
    "def normalize_for_model(image: xr.DataArray) -> xr.DataArray:\n",
    "    image_data = image.data\n",
    "    image_data = da.map_blocks(normalize_chunk, image_data, dtype=np.float32)\n",
    "    return image.copy(deep=False,\n",
    "                      data=image_data)\n",
    "\n",
    "image_model = rechunk_for_model(image_mosaic, model.input_shape)\n",
    "image_model = normalize_for_model(image_model)\n",
    "image_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the model is passed over the chunks of the image. Note `da.blockwise`, like map_blocks, but mucho more flexible (and difficult)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def patch_and_predict(chunk: np.ndarray, model: Model):\n",
    "    # Generate patches\n",
    "    patches = view_as_blocks(chunk, model.input_shape)\n",
    "    # Ignore blocks for channel\n",
    "    patches = patches[:, :, 0]\n",
    "    # Predict\n",
    "    prediction = model.predict(patches)\n",
    "    return prediction\n",
    "\n",
    "def predict_image(image: xr.DataArray, model: Model) -> xr.DataArray:\n",
    "    image_data = image.data\n",
    "    predicted_data = da.blockwise(lambda x: patch_and_predict(x, model), 'yxc', image.data, 'yxc',\n",
    "                                       meta=image_data._meta,\n",
    "                                       name='patch-and-predict',\n",
    "                                       adjust_chunks={'y': lambda y: y * model.output_shape[0] // model.input_shape[0],\n",
    "                                                      'x': lambda x: x * model.output_shape[1] // model.input_shape[1],\n",
    "                                                      'c': lambda _: model.output_shape[2]})\n",
    "    return xr.DataArray(data=predicted_data,\n",
    "                       dims=('y', 'x', 'band'),\n",
    "                       coords={\n",
    "                           'band': ['red', 'green', 'blue']\n",
    "                       })\n",
    "\n",
    "predicted_image = predict_image(image_model, model)\n",
    "predicted_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Napari could be used for painting the results. If it were working on my computer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03272428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%gui qt5\n",
    "#import napari\n",
    "# viewer = napari.view_image(predicted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, at the moment, let's just save the result. That will trigger all the computation.\n",
    "\n",
    "By the way, you can check the progress in the client's dashboard."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "netcdf_path = BASE_PATH + \"/data/results.nc\"\n",
    "predicted_image.transpose(\"band\", \"y\", \"x\").to_dataset(name=\"prediction\").to_netcdf(netcdf_path, engine=\"netcdf4\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
